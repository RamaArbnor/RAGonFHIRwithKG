{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG WITH FHIR DATA LEVERAGING KNOWLEDGE GRAPHS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\STORM\\AppData\\Local\\Temp\\ipykernel_26120\\3413308376.py:43: DeprecationWarning: write_transaction has been renamed to execute_write\n",
      "  session.write_transaction(clear_database)\n",
      "C:\\Users\\STORM\\AppData\\Local\\Temp\\ipykernel_26120\\3413308376.py:47: DeprecationWarning: write_transaction has been renamed to execute_write\n",
      "  session.write_transaction(load_bundle, cleaned_json_string)\n",
      "C:\\Users\\STORM\\AppData\\Local\\Temp\\ipykernel_26120\\3413308376.py:53: DeprecationWarning: write_transaction has been renamed to execute_write\n",
      "  session.write_transaction(create_relationships)\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "# Set up Neo4j connection\n",
    "uri = os.getenv(\"NEO4J_URI\", \"\")\n",
    "username = os.getenv(\"NEO4J_USERNAME\", \"\")\n",
    "password = os.getenv(\"NEO4J_PASSWORD\", \"\")\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "\n",
    "# Function to remove 'text.display' fields\n",
    "def remove_text_display(data):\n",
    "    for entry in data.get(\"entry\", []):\n",
    "        resource = entry.get(\"resource\", {})\n",
    "        if \"text\" in resource and \"display\" in resource[\"text\"]:\n",
    "            del resource[\"text\"][\"display\"]\n",
    "    return data\n",
    "\n",
    "# Load and preprocess FHIR JSON file\n",
    "with open(r\"C:\\Users\\STORM\\Documents\\GitHub\\RAGwithFHIR\\Dataset\\Bart73_King743_26b2b916-50a8-2b98-71b0-3150050312c8.json\", \"r\") as file:\n",
    "    fhir_data = json.load(file)\n",
    "\n",
    "# Clean the data by removing 'text.display' fields\n",
    "cleaned_data = remove_text_display(fhir_data)\n",
    "\n",
    "# Functions for Neo4j database interactions\n",
    "\n",
    "# 1. Clear the database\n",
    "def clear_database(tx):\n",
    "    tx.run(\"MATCH (n) DETACH DELETE n\")\n",
    "\n",
    "# 2. Load FHIR data using CyFHIR\n",
    "def load_bundle(tx, json_string):\n",
    "    tx.run(\"CALL cyfhir.bundle.load($json, {validation: true, version: 'R4'})\", json=json_string)\n",
    "\n",
    "\n",
    "# Execute script\n",
    "with driver.session() as session:\n",
    "    # Clear the database\n",
    "    session.write_transaction(clear_database)\n",
    "    \n",
    "    # Load the cleaned FHIR data as a JSON string\n",
    "    cleaned_json_string = json.dumps(cleaned_data)\n",
    "    session.write_transaction(load_bundle, cleaned_json_string)\n",
    "    \n",
    "    # Add indexes\n",
    "    # session.write_transaction(add_indexes)\n",
    "    \n",
    "    # Create relationships for structured knowledge graph\n",
    "    session.write_transaction(create_relationships)\n",
    "\n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed: MATCH (n:resource {resourceType: 'Condition'}) SET n:Condition\n",
      "Executed: MATCH (n:resource {resourceType: 'Observation'}) SET n:Observation\n",
      "Executed: MATCH (n:resource {resourceType: 'Medication'}) SET n:Medication\n",
      "Executed: MATCH (n:resource {resourceType: 'Patient'}) SET n:Patient\n",
      "Executed: MATCH (n:resource {resourceType: 'MedicationRequest'}) SET n:MedicationRequest\n"
     ]
    }
   ],
   "source": [
    "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "\n",
    "# Define queries\n",
    "queries = [\n",
    "    \"MATCH (n:resource {resourceType: 'Condition'}) SET n:Condition\",\n",
    "    \"MATCH (n:resource {resourceType: 'Observation'}) SET n:Observation\",\n",
    "    \"MATCH (n:resource {resourceType: 'Medication'}) SET n:Medication\",\n",
    "    \"MATCH (n:resource {resourceType: 'Patient'}) SET n:Patient\",\n",
    "    \"MATCH (n:resource {resourceType: 'MedicationRequest'}) SET n:MedicationRequest\",\n",
    "\n",
    "]\n",
    "\n",
    "# Function to run each query\n",
    "def tag_resources(driver, queries):\n",
    "    with driver.session() as session:\n",
    "        for query in queries:\n",
    "            session.run(query)\n",
    "            print(f\"Executed: {query}\")\n",
    "\n",
    "# Run the tagging queries\n",
    "tag_resources(driver, queries)\n",
    "\n",
    "# Close the driver connection\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating embedding text for patient node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "\n",
    "def create_patient_embedding(driver):\n",
    "    query = \"\"\"\n",
    "        MATCH (p:Patient)\n",
    "        OPTIONAL MATCH (p)-[:address]->(a)\n",
    "        OPTIONAL MATCH (p)-[:maritalStatus]->(m)\n",
    "        OPTIONAL MATCH (p)-[:name]->(n)\n",
    "        RETURN \n",
    "            n.given as name,\n",
    "            n.family as lname,\n",
    "            p.gender AS gender,\n",
    "            p.birthDate AS birthdate,\n",
    "            a.city as city,\n",
    "            a.country as country,\n",
    "            a.state as state,\n",
    "            a.line as line,\n",
    "            m.text as marrigialStatus\n",
    "    \"\"\"\n",
    "\n",
    "    # Run the query and process results\n",
    "    with driver.session() as session:\n",
    "        result = session.run(query)\n",
    "        patient_info = []\n",
    "        \n",
    "        for record in result:\n",
    "            # Debugging: print the raw record to see what is returned\n",
    "            # print(\"Raw record:\", record)\n",
    "            \n",
    "            # Collect data from each record\n",
    "            name = record.get(\"name\", \"Unknown\")\n",
    "            lname = record.get(\"lname\", \"Unknown\")\n",
    "            gender = record.get(\"gender\", \"Not specified\")\n",
    "            birthdate = record.get(\"birthdate\", \"Unknown\")\n",
    "            marital_status = record.get(\"marrigialStatus\", \"Unknown\")\n",
    "            city = record.get(\"city\", \"Unknown\")\n",
    "            country = record.get(\"country\", \"Unknown\")\n",
    "            state = record.get(\"state\", \"Unknown\")\n",
    "            line = record.get(\"line\", \"Unknown\")\n",
    "            \n",
    "            # Debugging: check the values of fields\n",
    "            # print(f\"Name: {name}, Line: {line}, City: {city}, State: {state}, Country: {country}\")\n",
    "            \n",
    "            # Combine into one embedding text\n",
    "            address = f\"{line}, {city}, {state}, {country}\" if line != \"Unknown\" else f\"{city}, {state}, {country}\"\n",
    "            embedding_text = f\"Name: {name} {lname}, Address: {address}, Gender: {gender}, Birthdate: {birthdate}, Marital Status: {marital_status}\"\n",
    "            patient_info.append(embedding_text)\n",
    "\n",
    "        update_query = \"\"\"\n",
    "            MATCH (p:Patient)\n",
    "\n",
    "            SET p.embeddingText = $embedding_text\n",
    "        \"\"\"\n",
    "        session.run(update_query, embedding_text=embedding_text)\n",
    "\n",
    "        return patient_info\n",
    "\n",
    "# Get the patient embedding text\n",
    "patient_embeddingText = create_patient_embedding(driver)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector index from graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.embeddings.base import Embeddings\n",
    "# import requests  # Or use any necessary package to communicate with Ollama\n",
    "\n",
    "# class OllamaEmbeddings(Embeddings):\n",
    "#     def __init__(self, model_name=\"mxbai-embed-large\"):\n",
    "#         self.model_name = model_name\n",
    "\n",
    "#     def embed_text(self, text: str) -> list:\n",
    "#         # Call Ollama's API or local embedding function\n",
    "#         # Modify this code based on how you interact with Ollama\n",
    "#         response = requests.post(\n",
    "#             \"http://localhost:11434/api/embeddings\",  # Replace with Ollama's endpoint\n",
    "#             json={\"model\": self.model_name, \"text\": text}\n",
    "#         )\n",
    "#         if response.status_code == 200:\n",
    "#             return response.json()[\"embedding\"]\n",
    "#         else:\n",
    "#             raise ValueError(\"Error retrieving embedding from Ollama\")\n",
    "\n",
    "#     def embed_documents(self, texts: list) -> list:\n",
    "#         return [self.embed_text(text) for text in texts]\n",
    "    \n",
    "#     def embed_query(self, text: str) -> list:\n",
    "#         # Use the same embedding process for queries as for text\n",
    "#         return self.embed_text(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SentenceTransformersEmbeddings' from 'langchain.embeddings' (c:\\Users\\STORM\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain\\embeddings\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraphs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Neo4jGraph\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneo4j_vector\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Neo4jVector\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformersEmbeddings\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Load Sentence Transformers model\u001b[39;00m\n\u001b[0;32m      7\u001b[0m st_embeddings \u001b[38;5;241m=\u001b[39m SentenceTransformersEmbeddings(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall-MiniLM-L6-v2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'SentenceTransformersEmbeddings' from 'langchain.embeddings' (c:\\Users\\STORM\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain\\embeddings\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain.graphs import Neo4jGraph\n",
    "from langchain.vectorstores.neo4j_vector import Neo4jVector\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Specify the model from Hugging Face, e.g., \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "hf_embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create the vector index from the existing Neo4j graph\n",
    "vector_index = Neo4jVector.from_existing_graph(\n",
    "    hf_embeddings,\n",
    "    url=uri,\n",
    "    username=username,\n",
    "    password=password,\n",
    "    index_name='FHIR',\n",
    "    node_label=\"Patient\",  # Replace with the actual label of your nodes\n",
    "    text_node_properties=['embeddingText'],  # Properties to embed\n",
    "    embedding_node_property='embedding',  # Property to store embeddings in Neo4j\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
